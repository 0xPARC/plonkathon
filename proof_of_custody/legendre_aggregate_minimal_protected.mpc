#
# Prototype implementation for proof of custody MPC using SCALE-MAMBA
#
# https://github.com/KULeuven-COSIC/SCALE-MAMBA
#

import gmpy2

bytes_per_chunk = 512
bits_per_chunk = bytes_per_chunk * 8
subchunks_bytes = [48] * 10 + [32] * 1
subchunks_per_chunk = len(subchunks_bytes)
q = 4002409555221667393417789825735904156556882819939007885332058136124031650490837864442687629129015664037894272559787

testvector_bytesize = 2**21

num_of_chunks = testvector_bytesize / bytes_per_chunk
num_of_legendre_precomps = num_of_chunks

alpha = cint(2)

s1_clear = 81681675576458296592962468591882928755428982678791722607038851948490729063334486091225670288310900000245446919497
s2_clear = 2916627308348648697632072304536739276536969206688246345394492297082347834974240482267299733062954162022258929970924

s1 = sint(s1_clear)
s2 = sint(s2_clear)

###########################
#
# Open python code
#
###########################


def to_bytes(n, length, endianess='big'):
    h = '%x' % n
    s = ('0'*(len(h) % 2) + h).zfill(length*2).decode('hex')
    return s if endianess == 'big' else s[::-1]

def from_bytes(s, endianess='big'):
    return int((s if endianess == 'big' else s[::-1]).encode('hex'), 16)

def chunkify(x):
    chunks = [x[i:i + bytes_per_chunk] for i in range(0, len(x), bytes_per_chunk)]
    chunks[-1] = chunks[-1].ljust(bytes_per_chunk, b"\0")
    return chunks

def bitarray_to_bytes(x):
    c = 0
    ret = b""
    for i, b in enumerate(x):
        c += b << (i % 8)
        if i % 8 == 7:
            ret += to_bytes(c,1,"little")
            c = 0
    if i % 8 != 7:
        ret += to_bytes(c,1,"little")
    return ret

def generate_test_vector(bytelength):
    ints = bytelength // 4
    return b"".join(to_bytes(i, 4, "little") for i in range(ints))

def subchunkify(x):
    subchunks = []
    start = 0
    for size in subchunks_bytes:
        subchunks.append(x[start:start + size])
        start += size
    return subchunks

def jacobi_bit_mpz(a, n):
    return (gmpy2.jacobi(a, n) + 1) // 2

def legendre_aggregate_chunk_mpz(x, s1, s2):
    subchunks = subchunkify(x)
    bits = []
    for i, subchunk in enumerate(subchunks):
        a = from_bytes(subchunk, "little")
        bits.append(jacobi_bit_mpz((i + 1) * (s1 if i % 2 == 0 else s2) + a, q))
    return sum(bits) % 2

def legendre_aggregate_mpz_first_round(x, s1, s2):
    bits = [legendre_aggregate_chunk_mpz(chunk, s1, s2) for chunk in chunkify(x)]
    return bitarray_to_bytes(bits)

def legendre_aggregate_mpz(x, s1, s2):
    return jacobi_bit_mpz(from_bytes(legendre_aggregate_mpz_first_round(x, s1, s2), "little"), q)

test_vector = generate_test_vector(num_of_chunks * bytes_per_chunk)

open_result = legendre_aggregate_mpz(test_vector,gmpy2.mpz(s1_clear),gmpy2.mpz(s2_clear))
open_result_first_round = legendre_aggregate_mpz_first_round(test_vector, gmpy2.mpz(s1_clear), gmpy2.mpz(s2_clear))
#print([legendre_aggregate_chunk_mpz(chunk,gmpy2.mpz(s1_clear),gmpy2.mpz(s2_clear)) for chunk in chunkify(test_vector)])
open_result_first_round_modq = from_bytes(open_result_first_round, "little") % q - q
#print(open_result_first_round_modq)

###########################
#
# Secret code
#
###########################

def secret_legendre(a, t, b):
    u = reveal(t * a)
    l = u.legendre()
    return l * (2 * b - 1)

def legendre_to_bit(l):
        return (l + 1) / 2

def precomp():
    s, ss = sint.get_random_square()
    b = sint.get_random_bit()
    t = ss * (b + alpha * (1 - b))
    return t, b

def secret_legendre_bit(a, t, b):
    return legendre_to_bit(secret_legendre(a, t, b))

def prod_reduce(l):
    if len(l) == 1:
        return l[0]
    return prod_reduce(l[:len(l)/2]) * prod_reduce(l[len(l)/2:])

# Precompute
start_timer(0)

pre_squares = Array(num_of_legendre_precomps, sint)
pre_bits = Array(num_of_legendre_precomps, sint)

for i in range(num_of_legendre_precomps):
    t, b = precomp()
    pre_squares[i] = t
    pre_bits[i] = b

discard, secret_square = sint.get_random_square()

stop_timer(0)

index = MemValue(regint(0))

# Round 1
start_timer(1)

chunks = chunkify(test_vector)
subchunks = [subchunkify(x) for x in chunks]
subchunks_reg = Array(num_of_chunks * subchunks_per_chunk, cint)
for i in range(num_of_chunks):
    for j in range(subchunks_per_chunk):
        subchunks_reg[i * subchunks_per_chunk + j] = from_bytes(subchunks[i][j], "little")

round_1_reg = Array(1, sint)
pow2_reg = Array(1, cint)
pow2_reg[0] = cint(1)

concurrent = 256 #Note: needs to divide num_of_chunks

@for_range(num_of_chunks / concurrent)
def g(i):
    for k in range(concurrent):
        factors = []
        for j in range(subchunks_per_chunk):
            index = (i * concurrent + k) * subchunks_per_chunk + j
            if j % 2 == 0:
                factors.append(subchunks_reg[index] + (j + 1) * s1)
            else: 
                factors.append(subchunks_reg[index] + (j + 1) * s2)

        prod = prod_reduce(factors)
        t, b = pre_squares[i * concurrent + k], pre_bits[i * concurrent + k]
        r = (-1) ** (subchunks_per_chunk + 1) * secret_legendre(prod, t, b)
        round_1_reg[0] += legendre_to_bit(r) * pow2_reg[0] * 2 ** k

    pow2_reg[0] *= 2 ** concurrent
    
print_ln("Result first round: %s", round_1_reg[0].reveal())
print_ln("Expected: %s", open_result_first_round_modq)

stop_timer(1)

# Final round
start_timer(2)

x = secret_square * round_1_reg[0]
y = x.reveal()
result = legendre_to_bit(y.legendre())

print_ln("Final result: %s", result)
print_ln("Expected: %s", open_result)

stop_timer(2)